{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Fake News on Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'import_ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b3044ed1f54e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'import_ipynb'"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns # for visualiation\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import altair as alt\n",
    "alt.renderers.enable('notebook')\n",
    "\n",
    "df = pd.read_csv('./facebook_with_reactions.csv')\n",
    "outcomes = df[['Rating']]\n",
    "\n",
    "## drop useless columns \n",
    "df = df.drop(columns=['Debate', 'status_link', 'permalink_url', 'Post URL', \n",
    "                      'status_message', 'link_name', 'share_count', 'Unnamed: 0', 'account_id',\n",
    "                      'status_id', 'status_type', 'status_published', 'post_id', 'reaction_count', 'Date Published'])\n",
    "\n",
    "# new columns\n",
    "df['Popular'] = df.num_comments + df.num_likes + df.num_shares\n",
    "\n",
    "## change Rating to numeric for classification\n",
    "df['Rating'] = df.Rating.replace(['mostly false', 'no factual content', 'mixture of true and false', 'mostly true'], [0,1,2,3])\n",
    "df['Rating2'] = df.Rating.replace([0,1,2,3], [0,0,0,1]).astype(int)\n",
    "\n",
    "## remove spaces in columns\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "\n",
    "# get dummy variables for categorical columns\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train and test data that uses 4 categories for Ranking (our outcome variable)\n",
    "tr_feat, test_feat, tr_out, test_out = train_test_split(\n",
    "   df.drop(columns=['Rating', 'Rating2']),      # features\n",
    "   df.Rating,    # outcome\n",
    "   random_state=0,\n",
    "   test_size=0.20, # percentage of data to use as the test set\n",
    "   \n",
    ")\n",
    "\n",
    "# train and test data that uses 2 categories for outcome variable\n",
    "tr2_feat, test2_feat, tr2_out, test2_out = train_test_split(\n",
    "   df.drop(columns=['Rating', 'Rating2']),      # features\n",
    "   df.Rating2,    # outcome\n",
    "   random_state=0,\n",
    "   test_size=0.20, # percentage of data to use as the test set\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this Notebook is to demonstrate the process we went through to answer our research question. We wanted to explore Facebook post popularity and its relationship with Fake News. Specifically, we wanted to know if there was a relationship between popularity and Fake News and take that a step further and see if we can predict if something is misinformation based on its popularity in addition to some other factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add visulizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(df.Rating)\n",
    "ax.set_title('Number of Posts in each Rating');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "corr = df.corr()\n",
    "ax = plt.axes()\n",
    "ax.set_title('Correlation Heatmap')\n",
    "sns.heatmap(corr, cmap='bwr', ax = ax,\n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot that shows counts of ratings colored based on the type of post i.e. video, link, text, etc.\n",
    "alt.Chart(df).mark_bar(size=50).encode(\n",
    "    x='Rating',\n",
    "    y='count()',\n",
    "    color='Post_Type'\n",
    ").properties(width=300, height=300, title='Rating by Post Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_bar(size=50).encode(\n",
    "    x='Category',\n",
    "    y='count()',\n",
    "    color='Page'\n",
    ").properties(width=300, height=300, title='Category by Page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = plt.bar(df.Rating, df.num_shares)\n",
    "p2 = plt.bar(df.Rating, df.num_likes)\n",
    "p3 = plt.bar(df.Rating, df.num_comments)\n",
    "\n",
    "ind = np.arange(5)\n",
    "\n",
    "plt.ylabel('Popularity')\n",
    "plt.title('Popularity by Rating')\n",
    "\n",
    "plt.xticks(ind, ('False', 'Non-Factual', 'True and False', 'Mostly True'))\n",
    "\n",
    "plt.legend((p1[0], p2[0], p3[0]), ('Shares', 'Likes', 'Comments'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='sag',\n",
    "                         multi_class='multinomial').fit(tr_feat, tr_out)\n",
    "\n",
    "clf2 = LogisticRegression(random_state=0, solver='sag',\n",
    "                         multi_class='multinomial').fit(tr2_feat, tr2_out)\n",
    "\n",
    "print('accuracy using 2 outcome categories: ' + str(round(clf2.score(test2_feat, test2_out), 2))\n",
    "     + '\\naccuracy using 4 outcome categories: ' + str(round(clf.score(test_feat, test_out), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "tar = ['mostly false', 'no factual content', 'mixture of true and false', 'mostly true']\n",
    "\n",
    "pred = clf.predict(test_feat)\n",
    "print('Using four classes:\\n')\n",
    "print(classification_report(test_out, pred, target_names=tar))\n",
    "\n",
    "print('-------------------------------------------------------------------\\n')\n",
    "print('Using two classes:\\n')\n",
    "pred = clf2.predict(test2_feat)\n",
    "print(classification_report(test2_out, pred, target_names=['False', 'True']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use selectkbest to get the best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier\n",
    "- Justin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "- Connie "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron\n",
    "- For the MLP classifier, we defined several parameters within a GridSearch to select the best MLP model. These parameters included `activation`, `learning_rate`, `hidden_layer_sizes`, and the `solver`. We set the activation to choose between relu and logistic because these are able to converge the fastest and generally give good predictions for smaller data sets. We wanted adaptive learning to see if the model could pick up on any complex changes in the sampling of data. We also let the model choose between a couple solvers that we saw provided the highest scores. As for the hidden layer sizes, they roughly follow the width of our data and seemed to perform better than other iterations of the model. We also made sure the MLP classifier shuffled samples and used cross validation to ensure accuracy. For feature selection, we decided to use _Select K Best_ with the `f_classif` solver and wanted anywhere from 5 to 25 (the width of our data) features. Before the model is ran we also used a Robust Scaler for data normalization and used the default (25, 75) or Inter-Quartile Range parameter. Shown below, we can see the results generated from this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import MLP as m;\n",
    "clf = m.mlp.fit(tr_feat, tr_out)\n",
    "clf2 = m.mlp.fit(tr2_feat, tr2_out)\n",
    "\n",
    "clf.score(test_feat, test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('MLP Model With Four Classes')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Actual')\n",
    "plt.scatter(mlp_4class.predict(test2_feat), test2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.score(test2_feat, test2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('MLP Model With Two Classes')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Actual')\n",
    "plt.scatter(clf.predict(test_feat), test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - add results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
