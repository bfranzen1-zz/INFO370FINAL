{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5decefe1560f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[0mlist_tup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m     \u001b[0mscrapeFacebookPostStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_tup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccess_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-5decefe1560f>\u001b[0m in \u001b[0;36mscrapeFacebookPostStatus\u001b[1;34m(post_list, access_token)\u001b[0m\n\u001b[0;32m    244\u001b[0m                     \u001b[1;34m\"status_link\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"permalink_url\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"status_published\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"num_reactions\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                     \u001b[1;34m\"num_comments\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"num_shares\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"num_likes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"num_loves\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m                     \"num_wows\", \"num_hahas\", \"num_sads\", \"num_angrys\"])\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'scraping...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "# READ ME #\n",
    "# This code was sourced from the following Facebook Scraping walkthrough: \n",
    "# https://nocodewebscraping.com/facebook-scraper/ by Paulo \n",
    "# To reproduce our data scraping pipeline, you will need to go through the \n",
    "# walkthrough and acquire your own access token from the Facebook Graph API.\n",
    "\n",
    "import urllib.request\n",
    "import json\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import util\n",
    "\n",
    "#app_id = \"<FILL IN>\"\n",
    "#app_secret = \"<FILL IN>\" # DO NOT SHARE WITH ANYONE!\n",
    "# page_id = raw_input(\"Please Paste Public Page Name:\")\n",
    "page_id = \"184096565021911\" # whatever facebook page you wish to uses\n",
    "\n",
    "\n",
    "# access_token = app_id + \"|\" + app_secret\n",
    "\n",
    "access_token = \"<FILL IN>\"\n",
    "\n",
    "def request_until_succeed(url):\n",
    "    req = urllib.request(url)\n",
    "    success = False\n",
    "    while success is False:\n",
    "        try: \n",
    "            response = urllib2.urlopen(req)\n",
    "            if response.getcode() == 200:\n",
    "                success = True\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            time.sleep(5)\n",
    "\n",
    "            #print \"Error for URL %s: %s\" % (url, datetime.datetime.now())\n",
    "            print (\"Retrying.\")\n",
    "\n",
    "    return response.read()\n",
    "\n",
    "def request_or_fail(url):\n",
    "    req = urllib2.Request(url)\n",
    "    success = False\n",
    "    try: \n",
    "        response = urllib2.urlopen(req)\n",
    "\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        return None\n",
    "        print (\"Error for URL %s: %s\" % (url, datetime.datetime.now()))\n",
    "        print (\"Retrying.\")\n",
    "\n",
    "    return response.read()\n",
    "\n",
    "# Needed to write tricky unicode correctly to csv\n",
    "def unicode_normalize(text):\n",
    "    return text.translate({ 0x2018:0x27, 0x2019:0x27, 0x201C:0x22, 0x201D:0x22,\n",
    "                            0xa0:0x20 }).encode('utf-8')\n",
    "\n",
    "def getFacebookPageFeedData(page_id, access_token, num_statuses):\n",
    "\n",
    "    # Construct the URL string; see http://stackoverflow.com/a/37239851 for\n",
    "    # Reactions parameters\n",
    "    base = \"https://graph.facebook.com/v2.6\"\n",
    "    node = \"/%s/posts\" % page_id \n",
    "    fields = \"/?fields=message,link,permalink_url,created_time,type,name,id,\" + \\\n",
    "            \"comments.limit(0).summary(true),shares,reactions\" + \\\n",
    "            \".limit(0).summary(true)\"\n",
    "    parameters = \"&limit=%s&access_token=%s\" % (num_statuses, access_token)\n",
    "    url = base + node + fields + parameters\n",
    "\n",
    "    # print url\n",
    "    # input('aa')\n",
    "    # retrieve data\n",
    "    request = request_until_succeed(url)\n",
    "    print (req)\n",
    "    if request == None:\n",
    "        data = None\n",
    "    else:\n",
    "        data = json.loads(request_until_succeed(url))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def getFacebookPostData(page_id, post_id, access_token,):\n",
    "    base = \"https://graph.facebook.com/v2.12\"\n",
    "    node = \"/%s_%s\" % (page_id, post_id)\n",
    "    fields = \"/?fields=message,created_time,type,name,id,\" + \\\n",
    "            \"comments.limit(0).summary(true),shares,reactions\" + \\\n",
    "            \".limit(0).summary(true)\"\n",
    "    parameters = \"&access_token=%s\" %  access_token\n",
    "    \n",
    "    url = base + node + fields + parameters\n",
    "\n",
    "    request = request_or_fail(url)\n",
    "    if request == None:\n",
    "        data = None\n",
    "    else:\n",
    "        data = json.loads(request)\n",
    "\n",
    "    \n",
    "    return data\n",
    "\n",
    "def getReactionsForStatus(status_id, access_token):\n",
    "\n",
    "    # See http://stackoverflow.com/a/37239851 for Reactions parameters\n",
    "        # Reactions are only accessable at a single-post endpoint\n",
    "\n",
    "    base = \"https://graph.facebook.com/v2.6\"\n",
    "    node = \"/%s\" % status_id\n",
    "    reactions = \"/?fields=\" \\\n",
    "            \"reactions.type(LIKE).limit(0).summary(total_count).as(like)\" \\\n",
    "            \",reactions.type(LOVE).limit(0).summary(total_count).as(love)\" \\\n",
    "            \",reactions.type(WOW).limit(0).summary(total_count).as(wow)\" \\\n",
    "            \",reactions.type(HAHA).limit(0).summary(total_count).as(haha)\" \\\n",
    "            \",reactions.type(SAD).limit(0).summary(total_count).as(sad)\" \\\n",
    "            \",reactions.type(ANGRY).limit(0).summary(total_count).as(angry)\"\n",
    "    parameters = \"&access_token=%s\" % access_token\n",
    "    url = base + node + reactions + parameters\n",
    "\n",
    "    # retrieve data\n",
    "    data = json.loads(request_until_succeed(url))\n",
    "     \n",
    "    return data\n",
    "\n",
    "\n",
    "def processFacebookPageFeedStatus(status, access_token):\n",
    "\n",
    "    # The status is now a Python dictionary, so for top-level items,\n",
    "    # we can simply call the key.\n",
    "\n",
    "    # Additionally, some items may not always exist,\n",
    "    # so must check for existence first\n",
    "\n",
    "    status_id = status['id']\n",
    "    status_message = '' if 'message' not in status.keys() else \\\n",
    "            unicode_normalize(status['message'])\n",
    "    link_name = '' if 'name' not in status.keys() else \\\n",
    "            unicode_normalize(status['name'])\n",
    "    status_type = status['type']\n",
    "    status_link = '' if 'link' not in status.keys() else \\\n",
    "            unicode_normalize(status['link'])\n",
    "    status_permalink_url = '' if 'permalink_url' not in status.keys() else \\\n",
    "            unicode_normalize(status['permalink_url'])\n",
    "    # Time needs special care since a) it's in UTC and\n",
    "    # b) it's not easy to use in statistical programs.\n",
    "\n",
    "    status_published = datetime.datetime.strptime(\n",
    "            status['created_time'],'%Y-%m-%dT%H:%M:%S+0000')\n",
    "    status_published = status_published + \\\n",
    "            datetime.timedelta(hours=-5) # EST\n",
    "    status_published = status_published.strftime(\n",
    "            '%Y-%m-%d %H:%M:%S') # best time format for spreadsheet programs\n",
    "\n",
    "    # Nested items require chaining dictionary keys.\n",
    "\n",
    "    num_reactions = 0 if 'reactions' not in status else \\\n",
    "            status['reactions']['summary']['total_count']\n",
    "    num_comments = 0 if 'comments' not in status else \\\n",
    "            status['comments']['summary']['total_count']\n",
    "    num_shares = 0 if 'shares' not in status else status['shares']['count']\n",
    "\n",
    "    # Counts of each reaction separately; good for sentiment\n",
    "    # Only check for reactions if past date of implementation:\n",
    "    # http://newsroom.fb.com/news/2016/02/reactions-now-available-globally/\n",
    "\n",
    "    reactions = getReactionsForStatus(status_id, access_token) if \\\n",
    "            status_published > '2016-02-24 00:00:00' else {}\n",
    "\n",
    "    num_likes = 0 if 'like' not in reactions else \\\n",
    "            reactions['like']['summary']['total_count']\n",
    "\n",
    "    # Special case: Set number of Likes to Number of reactions for pre-reaction\n",
    "    # statuses\n",
    "\n",
    "    num_likes = num_reactions if status_published < '2016-02-24 00:00:00' \\\n",
    "            else num_likes\n",
    "\n",
    "    def get_num_total_reactions(reaction_type, reactions):\n",
    "        if reaction_type not in reactions:\n",
    "            return 0\n",
    "        else:\n",
    "            return reactions[reaction_type]['summary']['total_count']\n",
    "\n",
    "    num_loves = get_num_total_reactions('love', reactions)\n",
    "    num_wows = get_num_total_reactions('wow', reactions)\n",
    "    num_hahas = get_num_total_reactions('haha', reactions)\n",
    "    num_sads = get_num_total_reactions('sad', reactions)\n",
    "    num_angrys = get_num_total_reactions('angry', reactions)\n",
    "\n",
    "    # Return a tuple of all processed data\n",
    "\n",
    "    return (status_id, status_message, link_name, status_type, status_link, status_permalink_url,\n",
    "            status_published, num_reactions, num_comments, num_shares,\n",
    "            num_likes, num_loves, num_wows, num_hahas, num_sads, num_angrys)\n",
    "\n",
    "\n",
    "def scrapeFacebookPageFeedStatus(page_id, access_token):\n",
    "    with open('facebook_statuses.csv' % page_id, 'wb') as file:\n",
    "        w = csv.writer(file)\n",
    "        w.writerow([\"status_id\", \"status_message\", \"link_name\", \"status_type\",\n",
    "                    \"status_link\", \"permalink_url\", \"status_published\", \"num_reactions\", \n",
    "                    \"num_comments\", \"num_shares\", \"num_likes\", \"num_loves\", \n",
    "                    \"num_wows\", \"num_hahas\", \"num_sads\", \"num_angrys\"])\n",
    "\n",
    "        has_next_page = True\n",
    "        num_processed = 0   # keep a count on how many we've processed\n",
    "        scrape_starttime = datetime.datetime.now()\n",
    "\n",
    "        print (\"Scraping %s Facebook Page: %s\\n\" % (page_id, scrape_starttime))\n",
    "        statuses = getFacebookPageFeedData(page_id, access_token, 100)\n",
    "\n",
    "        while has_next_page:\n",
    "            for status in statuses['data']:\n",
    "\n",
    "                # Ensure it is a status with the expected metadata\n",
    "                if 'reactions' in status:\n",
    "                    w.writerow(processFacebookPageFeedStatus(status,\n",
    "                        access_token))\n",
    "\n",
    "                # output progress occasionally to make sure code is not\n",
    "                # stalling\n",
    "                num_processed += 1\n",
    "                if num_processed % 100 == 0:\n",
    "                    print (\"%s Statuses Processed: %s\" % \\\n",
    "                        (num_processed, datetime.datetime.now()))\n",
    "            # if there is no next page, we're done.\n",
    "            if 'paging' in statuses.keys():\n",
    "                statuses = json.loads(request_until_succeed(\n",
    "                                        statuses['paging']['next']))\n",
    "            else:\n",
    "                has_next_page = False\n",
    "\n",
    "\n",
    "        print (\"\\nDone!\\n%s Statuses Processed in %s\" % \\\n",
    "                (num_processed, datetime.datetime.now() - scrape_starttime))\n",
    "def scrapeFacebookPostStatus(post_list, access_token):\n",
    "    with open('facebook_statuses.csv', 'wb') as file:\n",
    "        w = csv.writer(file)\n",
    "        w.writerow([\"status_id\", \"status_message\", \"link_name\", \"status_type\",\n",
    "                    \"status_link\", \"permalink_url\", \"status_published\", \"num_reactions\", \n",
    "                    \"num_comments\", \"num_shares\", \"num_likes\", \"num_loves\", \n",
    "                    \"num_wows\", \"num_hahas\", \"num_sads\", \"num_angrys\"])\n",
    "\n",
    "        print ('scraping...')\n",
    "        num_processed = 0\n",
    "        list_len = len(post_list)\n",
    "        for i in range(list_len):\n",
    "            (page_id, post_id) = post_list[i]\n",
    "            status = getFacebookPostData(page_id,post_id,access_token)\n",
    "             # Ensure it is a status with the expected metadata\n",
    "            if status != None:\n",
    "                if 'reactions' in status:\n",
    "                    num_processed+=1\n",
    "                    w.writerow(processFacebookPageFeedStatus(status,\n",
    "                        access_token))\n",
    "            if i % 100 == 0:\n",
    "                num = i / 100\n",
    "                print ('|' + '#'*num + ' '*(list_len/100 - num) + '|')\n",
    "        print (\"scraped %d posts1\" % num_processed)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    list_tup = util.postInfo()\n",
    "    scrapeFacebookPostStatus(list_tup, access_token)\n",
    "\n",
    "\n",
    "# The CSV can be opened in all major statistical programs. Have fun! :)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
